# app.py

import streamlit as st
import pandas as pd
import joblib
from io import BytesIO
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import os
import sys
from src.config import COLS_TO_EXCLUDE, PROGRAMDAKI_COLS, MEHMET_BEY_ATKI_COLS, MEHMET_BEY_COZGU_COLS, ALL_CSV_COLUMNS
from src.data_processing import load_and_prepare_base_data, normalize_columns, process_for_modeling
from src.model_training import train_and_evaluate_model

def get_data_folder_path(folder_name):
    """
    Program .exe olarak paketlendiÄŸinde veya normal script olarak Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda
    veri klasÃ¶rÃ¼nÃ¼n doÄŸru yolunu bulur.
    """
    if hasattr(sys, "_MEIPASS"):   
        # PyInstaller geÃ§ici bir klasÃ¶r oluÅŸturur ve dosyalarÄ± oraya Ã§Ä±karÄ±r.
        # sys._MEIPASS bu geÃ§ici klasÃ¶rÃ¼n yolunu iÃ§erir.
        return os.path.join(sys._MEIPASS, folder_name)
    
    # Normal bir .py scripti olarak Ã§alÄ±ÅŸtÄ±rÄ±ldÄ±ÄŸÄ±nda, mevcut dizini kullan.
    # Bu, geliÅŸtirme ortamÄ±nda Ã§alÄ±ÅŸmayÄ± kolaylaÅŸtÄ±rÄ±r.
    return folder_name
# YENÄ° EKLENEN KISIM SONU


# Streamlit sayfa ayarlarÄ±
st.set_page_config(layout="wide", page_title="AtkÄ±-Ã‡Ã¶zgÃ¼ Tahmin Modeli")
st.title("ğŸ§µ AtkÄ±-Ã‡Ã¶zgÃ¼ Ã‡ekme DeÄŸeri Tahmin ArayÃ¼zÃ¼")

# Session state yÃ¶netimi
if 'data_loaded' not in st.session_state:
    st.session_state.data_loaded = False
    st.session_state.base_data = None
    st.session_state.model = None
    st.session_state.model_cols = None
    st.session_state.target_col = None
    st.session_state.imputation_method = None

def read_data_file(uploaded_file):
    if uploaded_file is None: return None
    try:
        if uploaded_file.name.endswith('.csv'):
            try:
                df = pd.read_csv(uploaded_file, low_memory=False, encoding='utf-8-sig', header=0)
            except Exception:
                uploaded_file.seek(0); df = pd.read_csv(uploaded_file, low_memory=False, encoding='utf-8-sig', header=None)
                if len(df.columns) == len(ALL_CSV_COLUMNS): df.columns = ALL_CSV_COLUMNS
                else:
                    st.error(f"SÃ¼tun sayÄ±sÄ± uyuÅŸmazlÄ±ÄŸÄ±: Dosyada {len(df.columns)} sÃ¼tun var, config'de {len(ALL_CSV_COLUMNS)} bekleniyordu.")
                    return None
        elif uploaded_file.name.endswith(('.xlsx', '.xls')):
            df = pd.read_excel(uploaded_file)
        else:
            st.error("Desteklenmeyen dosya formatÄ±. LÃ¼tfen .csv veya .xlsx dosyasÄ± yÃ¼kleyin."); return None
        return normalize_columns(df)
    except Exception as e:
        st.error(f"Dosya okunurken bir hata oluÅŸtu: {e}"); return None

def align_columns(df, model_columns):
    missing_cols = set(model_columns) - set(df.columns)
    for c in missing_cols:
        df[c] = 0
    return df[model_columns]

# --- SIDEBAR ---
with st.sidebar:
    st.header("1. Veri YÃ¼kleme")
    
    # DEÄÄ°ÅTÄ°RÄ°LEN KISIM BAÅLANGICI
    # VarsayÄ±lan yolu, programÄ±n Ã§alÄ±ÅŸma ÅŸekline gÃ¶re (normal vs .exe) dinamik olarak belirle
    default_folder_path = get_data_folder_path("T3verileri")
    folder_path = st.text_input("EÄŸitim Veri KlasÃ¶rÃ¼nÃ¼n Yolu:", default_folder_path)
    # DEÄÄ°ÅTÄ°RÄ°LEN KISIM SONU
    
    if st.button("Verileri YÃ¼kle ve HazÄ±rla"):
        with st.spinner("Veriler okunuyor ve hazÄ±rlanÄ±yor..."):
            data, message = load_and_prepare_base_data(folder_path)
            if data is not None:
                st.session_state.base_data, st.session_state.data_loaded = data, True
                st.success(message)
            else:
                st.error(message); st.session_state.data_loaded = False

# --- ANA ARAYÃœZ ---
if st.session_state.data_loaded:
    df_base = st.session_state.base_data
    with st.sidebar:
        st.header("2. EÄŸitim Parametreleri")
        
        # --- DEÄÄ°ÅÄ°KLÄ°K BAÅLANGICI: Filtreleme SeÃ§eneÄŸi ---
        st.write("EÄŸitim Verisini Filtrele (Opsiyonel)")
        filtre_kriteri = st.radio(
            "Hangi Ã¶zelliÄŸe gÃ¶re filtrelemek istersiniz?",
            ("Filtreleme Yok", "Tip Koduna GÃ¶re", "KarÄ±ÅŸÄ±ma GÃ¶re"),
            horizontal=True
        )

        secilen_deger = None
        if filtre_kriteri == "Tip Koduna GÃ¶re":
            tip_kodlari = ["TÃ¼m Tipleri Kullan"] + sorted([str(tip) for tip in df_base["tip kodu"].unique() if pd.notna(tip)])
            secilen_deger = st.selectbox("Filtrelemek iÃ§in 'tip kodu' seÃ§in:", tip_kodlari)
        elif filtre_kriteri == "KarÄ±ÅŸÄ±ma GÃ¶re":
            if 'karisim' in df_base.columns:
                karisim_degerleri = ["TÃ¼m KarÄ±ÅŸÄ±mlarÄ± Kullan"] + sorted([str(k) for k in df_base["karisim"].unique() if pd.notna(k)])
                secilen_deger = st.selectbox("Filtrelemek iÃ§in 'karÄ±ÅŸÄ±m' seÃ§in:", karisim_degerleri)
            else:
                st.warning("'karisim' sÃ¼tunu veride bulunamadÄ±.")
                filtre_kriteri = "Filtreleme Yok"
        # --- DEÄÄ°ÅÄ°KLÄ°K SONU: Filtreleme SeÃ§eneÄŸi ---

        hedef_degisken = st.radio("Hangi DeÄŸer Tahmin Edilecek?", ("AtkÄ± Ã‡ekme (AtkÄ±SÄ±nÄ±f)", "Ã‡Ã¶zgÃ¼ Ã‡ekme (CozguSÄ±nÄ±f)"))
        algoritma = st.selectbox("KullanÄ±lacak AlgoritmayÄ± SeÃ§in:", ("Extra Trees Classifier", "Decision Tree Classifier"))
    
    st.subheader("Ã–zellik Seti ve Veri Ä°ÅŸleme YÃ¶ntemi")
    ozellik_secim_yontemi = st.radio(
        "Hangi yÃ¶ntemi kullanmak istersiniz?",
        ("Programdaki Ã–zellikler", 
         "Mehmet Bey'in SeÃ§tiÄŸi Ã–zellikler",
         "Manuel SeÃ§im"),
        horizontal=True, 
        help="Programdaki Ã¶zellikler iÃ§in eksik veri iÃ§eren satÄ±rlar silinir. Mehmet Bey'in ve Manuel seÃ§imde ise 0 ile doldurulur.")
    
    target_col = "AtkÄ±SÄ±nÄ±f" if "AtkÄ±" in hedef_degisken else "CozguSÄ±nÄ±f"
    base_feature_cols = sorted([col for col in df_base.columns if col not in COLS_TO_EXCLUDE and 'rolik numarasÄ±' not in col])
    
    if ozellik_secim_yontemi == "Programdaki Ã–zellikler":
        selected_cols = [col for col in PROGRAMDAKI_COLS if col in base_feature_cols]
        imputation_method = 'drop'
    elif ozellik_secim_yontemi == "Mehmet Bey'in SeÃ§tiÄŸi Ã–zellikler":
        source_cols = MEHMET_BEY_ATKI_COLS if target_col == "AtkÄ±SÄ±nÄ±f" else MEHMET_BEY_COZGU_COLS
        selected_cols = [col for col in source_cols if col not in COLS_TO_EXCLUDE and col in base_feature_cols]
        imputation_method = 'fill_zero' # <-- DEÄÄ°ÅÄ°KLÄ°K BURADA YAPILDI
    else: # ozellik_secim_yontemi == "Manuel SeÃ§im"
        excluded_cols = st.multiselect("Modelden Ã‡Ä±karÄ±lacak Ã–zellikler:", options=base_feature_cols)
        selected_cols = [col for col in base_feature_cols if col not in excluded_cols]
        imputation_method = 'fill_zero'

    st.markdown(f"Model iÃ§in **{len(selected_cols)}** Ã¶zellik seÃ§ildi.")
    st.markdown("---"); st.subheader("Model EÄŸitimi")
    if st.button("EÄŸitimi BaÅŸlat"):
        if not selected_cols: st.warning("LÃ¼tfen en az bir Ã¶zellik seÃ§in.")
        else:
            with st.spinner("Model eÄŸitiliyor..."):
                data_for_training = df_base.copy()
                
                # --- DEÄÄ°ÅÄ°KLÄ°K BAÅLANGICI: Filtreleme UygulamasÄ± ---
                if filtre_kriteri == "Tip Koduna GÃ¶re" and secilen_deger != "TÃ¼m Tipleri Kullan":
                    data_for_training = data_for_training[data_for_training['tip kodu'].astype(str) == secilen_deger]
                elif filtre_kriteri == "KarÄ±ÅŸÄ±ma GÃ¶re" and secilen_deger != "TÃ¼m KarÄ±ÅŸÄ±mlarÄ± Kullan":
                    data_for_training = data_for_training[data_for_training['karisim'].astype(str) == secilen_deger]
                # --- DEÄÄ°ÅÄ°KLÄ°K SONU: Filtreleme UygulamasÄ± ---
                
                X_train_ready, df_full = process_for_modeling(data_for_training, selected_cols, create_targets=True, fill_na_method=imputation_method)
                if X_train_ready.empty: st.error("Filtreleme ve Ã¶n iÅŸleme sonrasÄ± eÄŸitim iÃ§in veri kalmadÄ±.")
                elif len(df_full[target_col].unique()) < 2: st.error(f"EÄŸitim iÃ§in en az iki farklÄ± sÄ±nÄ±f (0 ve 1) gereklidir. Veride sadece '{df_full[target_col].unique()}' sÄ±nÄ±fÄ± bulundu.")
                else:
                    y_train_ready = df_full[target_col]
                    model, report, cm, acc, prec, rec, f1 = train_and_evaluate_model(X_train_ready, y_train_ready, algoritma)
                    st.session_state.update({'model': model, 'model_cols': list(X_train_ready.columns), 'target_col': target_col})
                    st.success("Model baÅŸarÄ±yla eÄŸitildi!")
                    st.subheader("--- EÄÄ°TÄ°M SETÄ° TEST SONUÃ‡LARI ---")
                    c1,c2,c3,c4 = st.columns(4); c1.metric("Accuracy",f"{acc:.4f}"); c2.metric("Precision",f"{prec:.4f}"); c3.metric("Recall",f"{rec:.4f}"); c4.metric("F1-score",f"{f1:.4f}")
                    st.write("#### DetaylÄ± Rapor"); st.dataframe(report.style.format("{:.4f}"))
                    st.write("#### KarÄ±ÅŸÄ±klÄ±k Matrisi"); st.dataframe(cm)

# --- TEST BÃ–LÃœMÃœ (Bu bÃ¶lÃ¼mde deÄŸiÅŸiklik yok) ---
if st.session_state.model:
    st.markdown("---"); st.subheader("EÄŸitilmiÅŸ Modeli Test Et")
    
    st.write("#### Test Verisi Ã–n Ä°ÅŸleme YÃ¶ntemi")
    test_imputation_choice = st.radio(
        "Test verisindeki eksik (boÅŸ) deÄŸerlere ne yapÄ±lsÄ±n?",
        ("BoÅŸ DeÄŸerleri 0 ile Doldur (TÃ¼m satÄ±rlar iÃ§in tahmin yapÄ±lÄ±r)", "BoÅŸ DeÄŸer Ä°Ã§eren SatÄ±rlarÄ± Sil (Sadece tam veriler tahmin edilir)"),
        horizontal=True,
        help="0 ile doldurma, tÃ¼m satÄ±rlar iÃ§in tahmin Ã¼retir. SatÄ±r silme ise sadece tam veriye sahip satÄ±rlar iÃ§in tahmin yapar."
    )
    
    test_na_method = 'drop' if "Sil" in test_imputation_choice else 'fill_zero'

    tab1, tab2, tab3 = st.tabs(["ğŸ¯ Tahmin (Etiketsiz Veri)", "ğŸ“Š DoÄŸrulama (Etiketli Veri)", "ğŸ’¾ Modeli DÄ±ÅŸa Aktar"])
    
    def handle_test_logic(df_raw, model, model_cols, create_targets, target_col, test_na_method):
        initial_rows = len(df_raw)
        if create_targets:
            X_ready, df_full = process_for_modeling(df_raw, model_cols, create_targets=True, fill_na_method=test_na_method)
        else:
            X_ready = process_for_modeling(df_raw, model_cols, create_targets=False, fill_na_method=test_na_method)
        if X_ready.empty:
            st.error("Ã–n iÅŸleme sonrasÄ± test edilecek veri kalmadÄ±. LÃ¼tfen dosyanÄ±zÄ± veya Ã¶n iÅŸleme yÃ¶nteminizi kontrol edin."); return
        if test_na_method == 'drop':
            rows_dropped = initial_rows - len(X_ready)
            if rows_dropped > 0:
                st.info(f"**Bilgi:** Test dosyanÄ±zdaki eksik veri iÃ§eren **{rows_dropped}** satÄ±r analizden Ã§Ä±karÄ±ldÄ±.")
        X_aligned = align_columns(X_ready, model_cols)
        y_pred = model.predict(X_aligned)
        if create_targets:
            y_true = df_full.loc[X_aligned.index, target_col]
            st.write("#### DoÄŸrulama Verisindeki SÄ±nÄ±f DaÄŸÄ±lÄ±mÄ±")
            class_distribution = y_true.value_counts()
            class_labels = {0: "SÄ±nÄ±f 0 (OK)", 1: "SÄ±nÄ±f 1 (HatalÄ±)"}
            class_distribution = class_distribution.rename(index=class_labels)
            st.dataframe(class_distribution)
            st.success(f"DoÄŸrulama tamamlandÄ±! {len(X_aligned)} satÄ±r Ã¼zerindeki performans:")
            acc=accuracy_score(y_true,y_pred); prec=precision_score(y_true,y_pred,zero_division=0); rec=recall_score(y_true,y_pred,zero_division=0); f1=f1_score(y_true,y_pred,zero_division=0)
            c1,c2,c3,c4 = st.columns(4); c1.metric("Accuracy",f"{acc:.4f}"); c2.metric("Precision",f"{prec:.4f}"); c3.metric("Recall",f"{rec:.4f}"); c4.metric("F1-score",f"{f1:.4f}")
        else:
            y_proba = model.predict_proba(X_aligned)
            df_res = pd.DataFrame({"Tahmin (0:OK, 1:HatalÄ±)": y_pred, "OK OlasÄ±lÄ±ÄŸÄ±": y_proba[:,0], "HatalÄ± OlasÄ±lÄ±ÄŸÄ±": y_proba[:,1]}, index=X_aligned.index)
            st.success(f"Tahminler {len(df_res)} satÄ±r iÃ§in oluÅŸturuldu."); 
            st.dataframe(df_res)
            st.subheader("Genel Ortalama OlasÄ±lÄ±klar")
            st.info("AÅŸaÄŸÄ±daki metrikler, yukarÄ±daki tablodaki tÃ¼m satÄ±rlarÄ±n olasÄ±lÄ±klarÄ±nÄ±n ortalamasÄ±nÄ± gÃ¶stermektedir.")
            avg_ok_proba = df_res["OK OlasÄ±lÄ±ÄŸÄ±"].mean()
            avg_hatali_proba = df_res["HatalÄ± OlasÄ±lÄ±ÄŸÄ±"].mean()
            col1, col2 = st.columns(2)
            with col1:
                st.metric(label="Ortalama 'OK' OlasÄ±lÄ±ÄŸÄ±", value=f"{avg_ok_proba:.2%}")
            with col2:
                st.metric(label="Ortalama 'HatalÄ±' OlasÄ±lÄ±ÄŸÄ±", value=f"{avg_hatali_proba:.2%}")

    with tab1:
        up_predict_file = st.file_uploader("Tahmin edilecek dosyayÄ± yÃ¼kleyin:", type=["csv","xlsx","xls"], key="up_predict")
        if st.button("Tahmin Et", key="btn_predict"):
            if up_predict_file:
                df_raw = read_data_file(up_predict_file)
                if df_raw is not None:
                    handle_test_logic(df_raw, st.session_state.model, st.session_state.model_cols, create_targets=False, target_col=None, test_na_method=test_na_method)
            else: st.warning("LÃ¼tfen tahmin iÃ§in bir dosya yÃ¼kleyin.")

    with tab2:
        up_val_file = st.file_uploader("DoÄŸrulama yapÄ±lacak dosyayÄ± yÃ¼kleyin:", type=["csv","xlsx","xls"], key="up_validate")
        if st.button("DoÄŸrulama Yap", key="btn_validate"):
            if up_val_file:
                df_raw = read_data_file(up_val_file)
                if df_raw is not None:
                    handle_test_logic(df_raw, st.session_state.model, st.session_state.model_cols, create_targets=True, target_col=st.session_state.target_col, test_na_method=test_na_method)
            else: st.warning("LÃ¼tfen doÄŸrulama iÃ§in bir dosya yÃ¼kleyin.")

    with tab3:
        st.info("EÄŸitilmiÅŸ modeli ve kullandÄ±ÄŸÄ± sÃ¼tun listesini bilgisayarÄ±nÄ±za indirin.")
        c1, c2 = st.columns(2)
        model_bytes = BytesIO(); joblib.dump(st.session_state.model, model_bytes); model_bytes.seek(0)
        c1.download_button(label="ğŸ¤– Modeli Ä°ndir (.pkl)", data=model_bytes, file_name="egitilmis_model.pkl")
        cols_bytes = BytesIO(); joblib.dump(st.session_state.model_cols, cols_bytes); cols_bytes.seek(0)
        c2.download_button(label="ğŸ“Š Model SÃ¼tunlarÄ±nÄ± Ä°ndir (.pkl)", data=cols_bytes, file_name="model_sutunlari.pkl")

st.markdown("---"); st.header("Harici Model ile Test")
up_ext_model = st.file_uploader("1. Model (.pkl)", type="pkl", key="ext_model")
up_ext_cols = st.file_uploader("2. Model SÃ¼tunlarÄ± (.pkl)", type="pkl", key="ext_cols")
up_ext_test = st.file_uploader("3. Test DosyasÄ± (CSV/XLSX)", type=["csv","xlsx","xls"], key="ext_csv")

if st.button("Harici Model ile Test Et", key="btn_ext_test"):
    if up_ext_model and up_ext_cols and up_ext_test:
        df_raw = read_data_file(up_ext_test)
        if df_raw is not None:
            try:
                model = joblib.load(up_ext_model); model_cols = joblib.load(up_ext_cols)
                handle_test_logic(df_raw, model, model_cols, create_targets=False, target_col=None, test_na_method=test_na_method)
            except Exception as e: st.error(f"Harici test sÄ±rasÄ±nda hata: {e}")
    else: st.warning("LÃ¼tfen 3 dosyayÄ± da yÃ¼kleyin.")